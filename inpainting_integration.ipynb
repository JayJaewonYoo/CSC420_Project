{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inpainting_integration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "25ad7CjG--r7"
      },
      "source": [
        "# install dependencies: \r\n",
        "!pip install pyyaml==5.1\r\n",
        "import torch, torchvision\r\n",
        "print(torch.__version__, torch.cuda.is_available())\r\n",
        "!gcc --version\r\n",
        "# opencv is pre-installed on colab\r\n",
        "\r\n",
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\r\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\r\n",
        "import torch\r\n",
        "assert torch.__version__.startswith(\"1.7\")\r\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\r\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPFxcAq7Xke"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "\"\"\"inpainting_integration.ipynb\r\n",
        "\r\n",
        "Automatically generated by Colaboratory.\r\n",
        "\r\n",
        "Original file is located at\r\n",
        "    https://colab.research.google.com/drive/1h3rJmx4XP97epAAtiM_peUmeI6FGX_yK\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy import ndimage\r\n",
        "from scipy import signal\r\n",
        "\r\n",
        "from detectron2 import model_zoo\r\n",
        "from detectron2.engine import DefaultPredictor\r\n",
        "from detectron2.config import get_cfg\r\n",
        "from detectron2.utils.visualizer import Visualizer\r\n",
        "from detectron2.data import MetadataCatalog\r\n",
        "\r\n",
        "from IPython.display import clear_output\r\n",
        "from google.colab.patches import cv2_imshow # For showing because cv2.imshow doesn't work normally\r\n",
        "\r\n",
        "# Based on:\r\n",
        "# https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/criminisi_cvpr2003.pdf\r\n",
        "\r\n",
        "class InpaintAlgorithm():\r\n",
        "    def __init__(self, image, labeled_masks, window_size=9, video=None, curr_frame=0):\r\n",
        "        labeled_mask = np.copy(labeled_masks[curr_frame])\r\n",
        "        assert image.shape[:2] == labeled_mask.shape, 'Image and mask must have same shape in 0 and 1 dimensions (HWC)'\r\n",
        "\r\n",
        "        # Original inputs (keeping just in case)\r\n",
        "        ######################\r\n",
        "        self.original_image = image.astype(np.float32)\r\n",
        "        # Image is read in as BGR format, may change to RGB later\r\n",
        "        self.original_labeled_mask = labeled_mask.astype(np.float32)\r\n",
        "        mask = np.copy(self.original_labeled_mask).astype(np.uint8)\r\n",
        "        mask[mask > 0] = 255\r\n",
        "        (threshold, self.original_mask) = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\r\n",
        "        self.all_detections = labeled_masks\r\n",
        "        self.all_detections[self.all_detections > 0] = 1\r\n",
        "        # Mask is binary [0, 255] with 255 inside target, 0 outside\r\n",
        "        ######################\r\n",
        "\r\n",
        "        # Values to be updated (not updated when computing priorities but must be updated after)\r\n",
        "        ######################\r\n",
        "        # Note that self.image and self.mask can be updated\r\n",
        "        self.image = np.copy(self.original_image)\r\n",
        "        # Image is read in as BGR format, may change to RGB later\r\n",
        "        self.mask = np.copy(self.original_mask)\r\n",
        "        self.labeled_mask = np.copy(self.original_labeled_mask)\r\n",
        "        self.video = np.copy(video)\r\n",
        "        self.curr_frame = curr_frame\r\n",
        "        # Mask is binary [0, 255] with 255 inside target, 0 outside\r\n",
        "        # 1 at edges, 0 otherwise\r\n",
        "        # self.fill_front = cv2.Canny(self.mask, 0, 255) / 255\r\n",
        "        contours, hierarchy = cv2.findContours(self.mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\r\n",
        "        self.fill_front = np.zeros_like(self.mask)\r\n",
        "        cv2.drawContours(self.fill_front, contours, -1, color=1, thickness=1)\r\n",
        "\r\n",
        "        # 0 inside target, 1 outside target\r\n",
        "        self.inv_mask = 1 - (np.copy(self.mask) / 255)\r\n",
        "        self.C = np.copy(self.inv_mask)  # 0 inside target, 1 outside target\r\n",
        "        ######################\r\n",
        "\r\n",
        "        # Constant Scalars\r\n",
        "        ######################\r\n",
        "        self.num_frames = 1 # Change later\r\n",
        "        self.window_size = window_size\r\n",
        "        # Enforce must be odd and positive\r\n",
        "        assert self.window_size % 2 != 0 and self.window_size > 0, 'Window size must be odd and positive'\r\n",
        "        # Default size in paper is 9 \"but in practice require the user to set it to be slightly larger than the largest texture element\"\r\n",
        "        self.alpha = 255\r\n",
        "        # self.window_area = np.square(self.window_size)\r\n",
        "        self.window_k = (self.window_size - 1) // 2  # Half of the window\r\n",
        "        self.image_height, self.image_width = self.mask.shape\r\n",
        "        ######################\r\n",
        "\r\n",
        "        # Constant Kernels\r\n",
        "        ######################\r\n",
        "        self.sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\r\n",
        "        self.sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\r\n",
        "        # For calculating normal of target edge\r\n",
        "        self.simple_grad_kernel_x = np.array([[0, 0, 0], [-1, 0, 1], [0, 0, 0]])\r\n",
        "        # For calculating normal of target edge\r\n",
        "        self.simple_grad_kernel_y = np.array([[0, -1, 0], [0, 0, 0], [0, 1, 0]])\r\n",
        "        # Used for quick confidences calculation\r\n",
        "        self.ones_window = np.ones((self.window_size, self.window_size))\r\n",
        "        self.normalization_array = signal.convolve2d(np.ones_like(self.mask), self.ones_window, mode='same', boundary='fill', fillvalue=0)  # Used for quick confidences calculation\r\n",
        "        ######################\r\n",
        "\r\n",
        "        # Arrays calculated using the above variables in the various function\r\n",
        "        ######################\r\n",
        "        self.grad_y = None  # Defined in compute_gradients()\r\n",
        "        self.grad_x = None  # Defined in compute_gradients()\r\n",
        "        self.edge_normal_y = None  # Defined in compute_normals()\r\n",
        "        self.edge_normal_x = None  # Defined in compute_normals()\r\n",
        "        self.data = None  # Defined in compute_data()\r\n",
        "        self.priorities = None  # Defined in compute_priorities()\r\n",
        "        self.subimage_source_regions = None # List of subimage source regions (idx corresponds to frame idx)\r\n",
        "        ######################\r\n",
        "\r\n",
        "    # Priority calculation functions\r\n",
        "    #################\r\n",
        "    def compute_gradients(self):\r\n",
        "        # If using lab, have to change this\r\n",
        "        grayscale_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\r\n",
        "        self.grad_y = ndimage.convolve(grayscale_image, self.sobel_y)\r\n",
        "        self.grad_x = ndimage.convolve(grayscale_image, self.sobel_x)\r\n",
        "\r\n",
        "    def compute_normals(self):\r\n",
        "        edge_grad_x = ndimage.convolve(self.inv_mask, self.simple_grad_kernel_x)\r\n",
        "        edge_grad_y = ndimage.convolve(self.inv_mask, self.simple_grad_kernel_y)\r\n",
        "        self.edge_normal_y = -1 * edge_grad_x\r\n",
        "        self.edge_normal_x = edge_grad_y\r\n",
        "        normal_magnitude = np.sqrt(np.square(self.edge_normal_y) + np.square(self.edge_normal_x))\r\n",
        "        # Prevent divide by 0 by not normalizing these elements\r\n",
        "        normal_magnitude[normal_magnitude == 0] = 1\r\n",
        "        self.edge_normal_y /= normal_magnitude\r\n",
        "        self.edge_normal_x /= normal_magnitude\r\n",
        "\r\n",
        "    def compute_data(self):\r\n",
        "        self.compute_gradients()\r\n",
        "        self.compute_normals()\r\n",
        "        data = (self.grad_y * self.edge_normal_y) + (self.grad_x * self.edge_normal_x)\r\n",
        "        data = np.abs(data)\r\n",
        "        data[data == 0] = 1e-7\r\n",
        "        # data *= self.fill_front # self.fill_front is assumed to be 1 at edges, 0 else\r\n",
        "        data /= self.alpha\r\n",
        "        self.data = data\r\n",
        "\r\n",
        "    def compute_confidences(self):\r\n",
        "        unnormalized_confidences = signal.convolve2d(self.C, self.ones_window, mode='same', boundary='fill', fillvalue=0)\r\n",
        "        confidences = unnormalized_confidences / self.normalization_array\r\n",
        "        # confidences *= self.fill_front # self.fill_front is assumed to be 1 at edges, 0 else\r\n",
        "        self.C = confidences\r\n",
        "\r\n",
        "    def compute_priorities(self):\r\n",
        "        self.compute_data()\r\n",
        "        self.compute_confidences()\r\n",
        "        # self.fill_front is assumed to be 1 at edges, 0 else\r\n",
        "        self.priorities = self.C * self.data * self.fill_front\r\n",
        "    #################\r\n",
        "\r\n",
        "    # Filling target patch functions\r\n",
        "    #################\r\n",
        "    def get_highest_priority_point(self):\r\n",
        "        # Return point corresponding to highest priority\r\n",
        "\r\n",
        "        \"\"\" Return coordinates for pixel with highest priority value \"\"\"\r\n",
        "        return np.unravel_index(self.priorities.argmax(), self.priorities.shape)\r\n",
        "\r\n",
        "    def get_target_patch(self, p):\r\n",
        "        # Return target patch and relevant information such as in-patch masks and coordinates for patch shape\r\n",
        "\r\n",
        "        y, x = p\r\n",
        "        if y - self.window_k < 0:\r\n",
        "            y_start_diff = self.window_k - y  # Positive, get y_start = y - y_start_diff\r\n",
        "        else:\r\n",
        "            y_start_diff = self.window_k\r\n",
        "        if x - self.window_k < 0:\r\n",
        "            x_start_diff = self.window_k - x  # Positive, x_start = x - x_start_diff\r\n",
        "        else:\r\n",
        "            x_start_diff = self.window_k\r\n",
        "        if y + self.window_k + 1 > self.image_height:\r\n",
        "            # Positive, y_end = y + y_end_diff\r\n",
        "            y_end_diff = self.image_height - (y + 1)\r\n",
        "        else:\r\n",
        "            y_end_diff = self.window_k + 1\r\n",
        "        if x + self.window_k + 1 > self.image_width:\r\n",
        "            # Positive, x_end = x + x_end_diff\r\n",
        "            x_end_diff = self.image_height - (x + 1)\r\n",
        "        else:\r\n",
        "            x_end_diff = self.window_k + 1\r\n",
        "\r\n",
        "        # y_start, y_end = max(0, y - self.window_k), min(self.image_height, y + self.window_k + 1) # row top, row bottom\r\n",
        "        # x_start, x_end = max(0, x - self.window_k), min(self.image_width, x + self.window_k + 1) # col left, col right\r\n",
        "        y_start = y - y_start_diff\r\n",
        "        x_start = x - x_start_diff\r\n",
        "        y_end = y + y_end_diff\r\n",
        "        x_end = x + x_end_diff\r\n",
        "\r\n",
        "        rel_coords = (y_start_diff, y_end_diff, x_start_diff, x_end_diff)\r\n",
        "\r\n",
        "        target_patch = np.copy(self.image[y_start:y_end, x_start:x_end])\r\n",
        "\r\n",
        "        patch_mask = np.copy(self.mask[y_start:y_end, x_start:x_end])\r\n",
        "        patch_mask[patch_mask == 255] = 1\r\n",
        "        patch_mask = 1 - patch_mask  # Patch mask is 1 in source, 0 in target\r\n",
        "\r\n",
        "        return target_patch, rel_coords, patch_mask\r\n",
        "\r\n",
        "    def get_person_idx(self, target_p):\r\n",
        "        # Finding person_idx to use\r\n",
        "        '''\r\n",
        "        print('Person idxs:', np.unique(self.labeled_mask))\r\n",
        "        print('Person idx at point:', self.labeled_mask[target_p])\r\n",
        "        print('Mask values', np.unique(self.mask))\r\n",
        "        print('Mask value at point:', self.mask[target_p])\r\n",
        "        '''\r\n",
        "\r\n",
        "        '''\r\n",
        "        person_idx = np.zeros_like(self.mask).astype(np.float32)\r\n",
        "        person_idx[target_p] = 1\r\n",
        "        person_idx *= self.labeled_mask\r\n",
        "        person_idx = np.unique(person_idx)\r\n",
        "        person_idx = person_idx[np.where(person_idx != 0)]\r\n",
        "\r\n",
        "        person_idx = person_idx[0].astype(int)\r\n",
        "        '''\r\n",
        "\r\n",
        "        person_idx = int(self.labeled_mask[target_p]) - 1 # Convert to 0-indexing instead of 1-indexing\r\n",
        "        assert person_idx >= 0, \"No detections found or bug with target_p not overlapping with labeled_mask\"\r\n",
        "\r\n",
        "        return person_idx\r\n",
        "\r\n",
        "    def define_subimage_sources(self):\r\n",
        "        # Idea is to provide a set of y, x coordinates to traverse\r\n",
        "\r\n",
        "        '''\r\n",
        "        # Increase size of labeled mask so that fill front is overlapped by it\r\n",
        "        for label in range(1, np.max(self.labeled_mask).astype(int) + 1):\r\n",
        "            label_y, label_x = np.where(self.labeled_mask == label)\r\n",
        "            self.labeled_mask[max(0, label_y.min() - 1):min(self.image_height - 1, label_y.max() + 1), \\\r\n",
        "                         max(0, label_y.min() - 1):min(self.image_width - 1, label_x.max() + 1)] = label\r\n",
        "        '''\r\n",
        "\r\n",
        "        # labeled_mask = np.copy(self.labeled_mask)\r\n",
        "\r\n",
        "        subimage_source_regions = [] # Each idx has coordinates for label idx + 1\r\n",
        "            # Coordinates are of form [(y_coords_1, x_coords_1), (y_coords_2, x_coords_2), ...]\r\n",
        "\r\n",
        "        # Defining subimage source region\r\n",
        "        for label in range(1, np.max(self.labeled_mask).astype(int) + 1):\r\n",
        "\r\n",
        "            # Get height and width of detection\r\n",
        "            labeled_mask = np.copy(self.labeled_mask)\r\n",
        "            label_y, label_x = np.where(labeled_mask == label)\r\n",
        "            box_height = label_y.max() - label_y.min() + 1\r\n",
        "            box_width = label_x.max() - label_x.min() + 1\r\n",
        "            \r\n",
        "            subimage = labeled_mask[max(0, label_y.min() - box_height):min(labeled_mask.shape[0] - 1, label_y.max() + box_height), \r\n",
        "                                    max(0, label_x.min() - box_width):min(labeled_mask.shape[1] - 1, label_x.max() + box_width)]\r\n",
        "            \r\n",
        "            subimage[subimage != label] = -label\r\n",
        "            \r\n",
        "            subimage_source_regions.append(np.where(labeled_mask == -label))\r\n",
        "\r\n",
        "        self.subimage_source_regions = subimage_source_regions\r\n",
        "\r\n",
        "        return\r\n",
        "\r\n",
        "    def find_optimal_source(self, target_patch, person_idx, rel_coords, patch_mask):\r\n",
        "        # Returns exemplar from source region\r\n",
        "\r\n",
        "        source_mask = np.copy(self.mask).astype(np.float32)\r\n",
        "\r\n",
        "        source_mask[source_mask == 255] = 1\r\n",
        "        source_fill = np.copy(source_mask).astype(np.float32)\r\n",
        "        source_mask = 1 - source_mask\r\n",
        "        # This stacking is probably inefficient and could be replaced\r\n",
        "        source_mask = np.stack([source_mask] * 3, axis=2)\r\n",
        "        # source_mask is 0 in target region, 1 in source region\r\n",
        "        # Use 500 to indicate if it is in target region or not, just an arbitrary number outside of BGR range\r\n",
        "        source_fill[source_fill == 1] = 500\r\n",
        "        source_fill = np.stack([source_fill] * 3, axis=2)\r\n",
        "        # source_fill is 500 in target region, 0 in source_region\r\n",
        "        source_image = (np.copy(self.image) * source_mask) + source_fill\r\n",
        "\r\n",
        "        patch_mask_3d = np.stack([patch_mask] * 3, axis=2)\r\n",
        "\r\n",
        "        min_score = best_patch_variance = np.inf\r\n",
        "        optimal_source_patch = None\r\n",
        "\r\n",
        "        y_start_diff, y_end_diff, x_start_diff, x_end_diff = rel_coords\r\n",
        "\r\n",
        "        curr_y_source_coords, curr_x_source_coords = self.subimage_source_regions[person_idx]\r\n",
        "\r\n",
        "        coord_idxs_to_keep = np.logical_and.reduce((curr_y_source_coords - y_start_diff >= 0, curr_x_source_coords - x_start_diff >= 0, curr_y_source_coords + y_end_diff < self.image_height - 1, curr_x_source_coords + x_end_diff < self.image_width - 1))\r\n",
        "        curr_y_source_coords = curr_y_source_coords[coord_idxs_to_keep]\r\n",
        "        curr_x_source_coords = curr_x_source_coords[coord_idxs_to_keep]\r\n",
        "        \r\n",
        "        best_i = 0 \r\n",
        "\r\n",
        "        for coord_idx in range(len(curr_y_source_coords)):\r\n",
        "            y = curr_y_source_coords[coord_idx]\r\n",
        "            x = curr_x_source_coords[coord_idx]\r\n",
        "\r\n",
        "            '''\r\n",
        "            y_start = max(0, y - y_start_diff)\r\n",
        "            x_start = max(0, x - x_start_diff)\r\n",
        "            y_end = min(self.image_height - 1, y + y_end_diff)\r\n",
        "            x_end = min(self.image_width - 1, x + x_end_diff)\r\n",
        "            '''\r\n",
        "            y_start = y - y_start_diff\r\n",
        "            x_start = x - x_start_diff\r\n",
        "            y_end = y + y_end_diff\r\n",
        "            x_end = x + x_end_diff\r\n",
        "\r\n",
        "            curr_source_patch = source_image[y_start:y_end, x_start:x_end, :]\r\n",
        "            if 500 in curr_source_patch:  # Invalid patch; not entirely bound in source region\r\n",
        "                continue\r\n",
        "            \r\n",
        "            if self.video is None:\r\n",
        "                curr_score = np.sum(np.square(curr_source_patch - target_patch) * patch_mask_3d)\r\n",
        "\r\n",
        "                patch_mean = np.zeros(3)\r\n",
        "                patch_mask = np.array(patch_mask, dtype=np.bool)\r\n",
        "\r\n",
        "                B = curr_source_patch[:,:,0]\r\n",
        "                patch_mean[0] = np.mean(B[patch_mask])\r\n",
        "                \r\n",
        "                G = curr_source_patch[:,:,1]\r\n",
        "                patch_mean[1] = np.mean(G[patch_mask])\r\n",
        "            \r\n",
        "                R = curr_source_patch[:,:,2]\r\n",
        "                patch_mean[2] = np.mean(R[patch_mask])\r\n",
        "\r\n",
        "                inv_patch_mask = np.invert(patch_mask)\r\n",
        "                w_mean, w_var = 1, 1\r\n",
        "                if curr_score <= min_score:\r\n",
        "                    patch_var = 0 \r\n",
        "                    patch_var += np.sum(np.square(B[inv_patch_mask] - patch_mean[0]))\r\n",
        "                    patch_var += np.sum(np.square(G[inv_patch_mask] - patch_mean[1]))\r\n",
        "                    patch_var += np.sum(np.square(R[inv_patch_mask] - patch_mean[2])) \r\n",
        "\r\n",
        "                    if curr_score < w_mean * min_score or patch_var < w_var * best_patch_variance:\r\n",
        "                        best_patch_variance = patch_var\r\n",
        "                        min_score = curr_score\r\n",
        "                        optimal_source_patch = curr_source_patch\r\n",
        "            else:\r\n",
        "                frame_window = 3 // 2\r\n",
        "                start_frame = self.curr_frame - frame_window\r\n",
        "                end_frame = self.curr_frame + frame_window + 1\r\n",
        "                \r\n",
        "                if start_frame < 0:\r\n",
        "                    diff = abs(start_frame)\r\n",
        "                    start_frame = 0\r\n",
        "                    end_frame += diff\r\n",
        "\r\n",
        "                video_len = len(self.video)\r\n",
        "                if end_frame > video_len:\r\n",
        "                    diff = end_frame - video_len\r\n",
        "                    start_frame -= diff\r\n",
        "                    end_frame = video_len\r\n",
        "                \r\n",
        "                source_patches = self.video[start_frame:end_frame, y_start:y_end, x_start:x_end]\r\n",
        "                source_patches[frame_window] = curr_source_patch\r\n",
        "                relevant_detections = self.all_detections[start_frame:end_frame, ...]\r\n",
        "\r\n",
        "                for i, source_patch in enumerate(source_patches):\r\n",
        "                    if relevant_detections[i, y, x] == 1:\r\n",
        "                        continue\r\n",
        "                    \r\n",
        "                    curr_score = np.sum(np.square(source_patch - target_patch) * patch_mask_3d)\r\n",
        "\r\n",
        "                    patch_mean = np.zeros(3)\r\n",
        "                    patch_mask = np.array(patch_mask, dtype=np.bool)\r\n",
        "\r\n",
        "                    B = source_patch[:,:,0]\r\n",
        "                    patch_mean[0] = np.mean(B[patch_mask])\r\n",
        "                    \r\n",
        "                    G = source_patch[:,:,1]\r\n",
        "                    patch_mean[1] = np.mean(G[patch_mask])\r\n",
        "                \r\n",
        "                    R = source_patch[:,:,2]\r\n",
        "                    patch_mean[2] = np.mean(R[patch_mask])\r\n",
        "\r\n",
        "                    inv_patch_mask = np.invert(patch_mask)\r\n",
        "                    w_mean, w_var = 1, 1\r\n",
        "                    if curr_score <= min_score:\r\n",
        "                        patch_var = 0 \r\n",
        "                        patch_var += np.sum(np.square(B[inv_patch_mask] - patch_mean[0]))\r\n",
        "                        patch_var += np.sum(np.square(G[inv_patch_mask] - patch_mean[1]))\r\n",
        "                        patch_var += np.sum(np.square(R[inv_patch_mask] - patch_mean[2])) \r\n",
        "\r\n",
        "                        if curr_score < w_mean * min_score or patch_var < w_var * best_patch_variance:\r\n",
        "                            best_patch_variance = patch_var\r\n",
        "                            min_score = curr_score\r\n",
        "                            optimal_source_patch = source_patch\r\n",
        "                            best_i = i\r\n",
        "        \r\n",
        "        assert optimal_source_patch is not None, \"Source region not found.\"\r\n",
        "        # print(\"Optimal Source Patch from Frame: \", self.curr_frame + best_i)\r\n",
        "        return optimal_source_patch\r\n",
        "\r\n",
        "    def update_image_arrays(self, optimal_source_patch, target_p, rel_coords, patch_mask):\r\n",
        "        # Update all image arrays\r\n",
        "\r\n",
        "        y, x = target_p\r\n",
        "\r\n",
        "        y_start_diff, y_end_diff, x_start_diff, x_end_diff = rel_coords\r\n",
        "        y_start = y - y_start_diff\r\n",
        "        x_start = x - x_start_diff\r\n",
        "        y_end = y + y_end_diff\r\n",
        "        x_end = x + x_end_diff\r\n",
        "\r\n",
        "        # Updating image\r\n",
        "        # patch_mask is 0 in target, 1 in source\r\n",
        "        # Make target area in image 0\r\n",
        "        # Make source area in patch 0\r\n",
        "        image_patch_mask = np.stack([patch_mask] * 3, axis=2)\r\n",
        "        self.image[y_start:y_end, x_start:x_end, :] = \\\r\n",
        "            (self.image[y_start:y_end, x_start:x_end, :] * image_patch_mask) + \\\r\n",
        "            (optimal_source_patch * (1 - image_patch_mask))\r\n",
        "\r\n",
        "        # Updating mask and related arrays\r\n",
        "        # Update patch to be source\r\n",
        "        # mask is 1 at edges, 0 otherwise\r\n",
        "        # inv_mask is 0 inside target, 1 outside target\r\n",
        "        self.mask[y_start:y_end, x_start:x_end] = 0\r\n",
        "        # self.fill_front = cv2.Canny(self.mask, 0, 255) / 255\r\n",
        "\r\n",
        "        contours, hierarchy = cv2.findContours(self.mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\r\n",
        "        self.fill_front = np.zeros_like(self.mask)\r\n",
        "        cv2.drawContours(self.fill_front, contours, -1, color=1, thickness=1)\r\n",
        "\r\n",
        "        self.inv_mask = 1 - (np.copy(self.mask) / 255)\r\n",
        "\r\n",
        "        # Updating C\r\n",
        "        # Only update in target region\r\n",
        "        C_origin = self.C[y, x] * np.ones_like(patch_mask)\r\n",
        "        self.C[y_start:y_end, x_start:x_end] = \\\r\n",
        "            (self.C[y_start:y_end, x_start:x_end] * patch_mask) + \\\r\n",
        "            (C_origin * (1 - patch_mask))\r\n",
        "\r\n",
        "    def update_image(self):\r\n",
        "        # Use priorities to update image\r\n",
        "\r\n",
        "        target_p = self.get_highest_priority_point()\r\n",
        "        target_patch, rel_coords, patch_mask = self.get_target_patch(target_p)\r\n",
        "        person_idx = self.get_person_idx(target_p)\r\n",
        "        optimal_source_patch = self.find_optimal_source(target_patch, person_idx, rel_coords, patch_mask)\r\n",
        "        self.update_image_arrays(optimal_source_patch, target_p, rel_coords, patch_mask)\r\n",
        "\r\n",
        "    def _do_inpainting_single(self):\r\n",
        "        # Perform one iteration of inpainting\r\n",
        "\r\n",
        "        self.compute_priorities()\r\n",
        "        self.update_image()\r\n",
        "\r\n",
        "    def do_inpainting(self):\r\n",
        "        # Perform all iterations of inpainting\r\n",
        "\r\n",
        "        self.define_subimage_sources()\r\n",
        "        while np.sum(self.fill_front) > 0:\r\n",
        "            print(np.sum(self.fill_front))\r\n",
        "\r\n",
        "            self._do_inpainting_single()\r\n",
        "            curr_image = self.image.astype(np.uint8)\r\n",
        "\r\n",
        "            # cv2_imshow(curr_image)\r\n",
        "            \r\n",
        "            # clear_output(wait=False)\r\n",
        "        return self.image\r\n",
        "    #################\r\n",
        "\r\n",
        "class InpaintVideo():\r\n",
        "    def __init__(self, video, mask, window_size=9):\r\n",
        "        \"\"\"\r\n",
        "        video: Video input T x H x W x C\r\n",
        "        mask: Video mask input T x H x W\r\n",
        "        \"\"\"\r\n",
        "        assert video.shape[:3] == mask.shape\r\n",
        "        \r\n",
        "        self.window_size = window_size\r\n",
        "\r\n",
        "        self.original_video = video\r\n",
        "        self.video = np.copy(self.original_video)\r\n",
        "\r\n",
        "        self.original_mask = mask\r\n",
        "        self.mask = np.copy(self.original_mask)\r\n",
        "\r\n",
        "    def inpaint_curr_frame(self, curr_frame):\r\n",
        "        inpaintAlgorithm = InpaintAlgorithm(self.video[curr_frame], self.mask, \\\r\n",
        "                                            self.window_size, self.original_video, curr_frame)\r\n",
        "        inpainted_frame = inpaintAlgorithm.do_inpainting()\r\n",
        "        \r\n",
        "        return inpainted_frame\r\n",
        "    \r\n",
        "    def inpaint(self):\r\n",
        "        for frame in range(self.video.shape[0]):\r\n",
        "            print(\"Frame \", frame)\r\n",
        "            inpainted_frame = self.inpaint_curr_frame(frame)\r\n",
        "            cv2_imshow(inpainted_frame)\r\n",
        "            self.video[frame] = inpainted_frame\r\n",
        "\r\n",
        "class PedestrianDetector():\r\n",
        "    def __init__(self, cascade_classifier='pedestrian.xml', do_video=False):\r\n",
        "        self.pedestrian_cascade = cv2.CascadeClassifier(cascade_classifier)\r\n",
        "\r\n",
        "        self.cfg = get_cfg()\r\n",
        "        self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\n",
        "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\r\n",
        "        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\r\n",
        "        self.predictor = DefaultPredictor(self.cfg)\r\n",
        "\r\n",
        "        self.do_video = do_video\r\n",
        "\r\n",
        "    def get_frame_masks_haar(self, video_src='pedestrians.avi', video_save_path='display.avi'):\r\n",
        "        # Video Capture object\r\n",
        "        cap = cv2.VideoCapture(video_src)\r\n",
        "\r\n",
        "        # Output video\r\n",
        "        frame_width = int(cap.get(3))\r\n",
        "        frame_height = int(cap.get(4))\r\n",
        "        size = (frame_width, frame_height)\r\n",
        "\r\n",
        "        if self.do_video:\r\n",
        "            video_writer = cv2.VideoWriter(video_save_path,\r\n",
        "                                    cv2.VideoWriter_fourcc(*'MJPG'),\r\n",
        "                                    10, size)\r\n",
        "        else:\r\n",
        "            class EmptyWriter():\r\n",
        "                def write(self, _):\r\n",
        "                    return\r\n",
        "                def release(self):\r\n",
        "                    return\r\n",
        "            \r\n",
        "            video_writer = EmptyWriter()\r\n",
        "\r\n",
        "        masks = []\r\n",
        "        frames = []\r\n",
        "\r\n",
        "        frame_number = 0\r\n",
        "\r\n",
        "        while True:\r\n",
        "            ret, img = cap.read()\r\n",
        "\r\n",
        "            if not ret:\r\n",
        "                break\r\n",
        "\r\n",
        "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "            # Get bounding boxes\r\n",
        "            bboxes = self.pedestrian_cascade.detectMultiScale(img_gray, 1.3, 2)\r\n",
        "\r\n",
        "            detections = np.array(bboxes)\r\n",
        "            mask = np.zeros_like(img_gray)\r\n",
        "\r\n",
        "            display = img.copy()\r\n",
        "            for idx, (x, y, w, h) in enumerate(bboxes, 1):\r\n",
        "                cv2.rectangle(display, (x, y), (x + w, y + h), (0, 255, 0), 4)\r\n",
        "                mask[y:y + h, x:x + w] = idx\r\n",
        "\r\n",
        "            frames.append(img)\r\n",
        "            masks.append(mask)\r\n",
        "            video_writer.write(display)\r\n",
        "\r\n",
        "            frame_number += 1\r\n",
        "\r\n",
        "        cap.release()\r\n",
        "        video_writer.release()\r\n",
        "\r\n",
        "        frames = np.stack(frames, axis=0)\r\n",
        "        masks = np.stack(masks, axis=0)\r\n",
        "\r\n",
        "        return frames, masks\r\n",
        "\r\n",
        "    def get_frame_masks_d2bbox(self, video_src='pedestrians.avi', video_save_path='display.avi'):\r\n",
        "        # Video Capture object\r\n",
        "        cap = cv2.VideoCapture(video_src)\r\n",
        "\r\n",
        "        # Output video\r\n",
        "        frame_width = int(cap.get(3))\r\n",
        "        frame_height = int(cap.get(4))\r\n",
        "        size = (frame_width, frame_height)\r\n",
        "\r\n",
        "        if self.do_video:\r\n",
        "            video_writer = cv2.VideoWriter(video_save_path,\r\n",
        "                                           cv2.VideoWriter_fourcc(*'MJPG'),\r\n",
        "                                           10, size)\r\n",
        "        else:\r\n",
        "            class EmptyWriter():\r\n",
        "                def write(self, _):\r\n",
        "                    return\r\n",
        "\r\n",
        "                def release(self):\r\n",
        "                    return\r\n",
        "\r\n",
        "            video_writer = EmptyWriter()\r\n",
        "\r\n",
        "        masks = []\r\n",
        "        frames = []\r\n",
        "\r\n",
        "        frame_number = 0\r\n",
        "\r\n",
        "        while True:\r\n",
        "            ret, img = cap.read()\r\n",
        "\r\n",
        "            if not ret:\r\n",
        "                break\r\n",
        "\r\n",
        "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "            outputs = self.predictor(img)\r\n",
        "            # Get bounding boxes\r\n",
        "            bboxes = outputs[\"instances\"].pred_boxes.to(\"cpu\")\r\n",
        "            classes = outputs[\"instances\"].pred_classes\r\n",
        "\r\n",
        "            mask = np.zeros_like(img_gray)\r\n",
        "\r\n",
        "            display = img.copy()\r\n",
        "            label = 1\r\n",
        "            for idx, (x1, y1, x2, y2) in enumerate(bboxes):\r\n",
        "                if MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]).thing_classes[classes[idx]] is not 'person':\r\n",
        "                    continue\r\n",
        "                x1, y1, x2, y2 = int(x1.item()), int(y1.item()), int(x2.item()), int(y2.item())\r\n",
        "                cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 0), 4)\r\n",
        "                mask[y1:y2, x1:x2] = label\r\n",
        "                label += 1\r\n",
        "\r\n",
        "            frames.append(img)\r\n",
        "            masks.append(mask)\r\n",
        "            video_writer.write(display)\r\n",
        "\r\n",
        "            frame_number += 1\r\n",
        "\r\n",
        "        cap.release()\r\n",
        "        video_writer.release()\r\n",
        "\r\n",
        "        frames = np.stack(frames, axis=0)\r\n",
        "        masks = np.stack(masks, axis=0)\r\n",
        "\r\n",
        "        return frames, masks\r\n",
        "\r\n",
        "class Inpainter():\r\n",
        "    def __init__(self, video_path, cascade_classifier='pedestrian.xml', do_video=False):\r\n",
        "        self.person_detector = PedestrianDetector(cascade_classifier, do_video)\r\n",
        "        self.video_frames, self.labeled_masks = self.person_detector.get_frame_masks_d2bbox(video_src=video_path)\r\n",
        "        \r\n",
        "        self.inpaintVideo = InpaintVideo(self.video_frames, self.labeled_masks, window_size=15)\r\n",
        "\r\n",
        "    def inpaint(self):\r\n",
        "        self.inpaintVideo.inpaint()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZTTdk9uU32q"
      },
      "source": [
        "test_image = np.load('video_frame.npy')\r\n",
        "test_mask = np.load('video_frame_mask.npy')\r\n",
        "test_mask[test_mask > 0] = 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKYcBB37smN"
      },
      "source": [
        "person_detector = PedestrianDetector('pedestrian.xml', False)\r\n",
        "video_frames, labeled_masks = person_detector.get_frame_masks_d2bbox('pedestrians.avi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2nQ0D5m7s_z"
      },
      "source": [
        "inpaintVideo = InpaintVideo(video_frames, labeled_masks, window_size=9)\r\n",
        "inpaintVideo.inpaint()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql_GdP3BXZzQ"
      },
      "source": [
        "cv2_imshow(inpaintVideo.video[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-7axab7vcF"
      },
      "source": [
        "for idx, frame in enumerate(inpaintVideo.video):\r\n",
        "    cv2.imwrite(frame, 'output/frame_%6d.png' % idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnVSFUZsp86p"
      },
      "source": [
        "cv2_imshow(video_frames[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25hJRM4bp_FZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}